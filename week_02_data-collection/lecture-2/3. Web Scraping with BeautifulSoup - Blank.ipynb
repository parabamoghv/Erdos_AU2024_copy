{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfacfff1",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup\n",
    "\n",
    "Sometimes there may not be an easily accessible data set for your project. However, there may be data that exists on the web which you can scrape. One way to do this in python is to use `BeautifulSoup`.\n",
    "\n",
    "## What we will accomplish in this notebook\n",
    "\n",
    "In this notebook we will:\n",
    "- Discuss the structure of HTML code,\n",
    "- Introduce the `bs4` pacakge,\n",
    "- Parse simple HTML code with `BeautifulSoup`,\n",
    "- Review how to request the HTML code from a url,\n",
    "- Scrape data from an actual webpage and\n",
    "- Touch on some of the issues that may arise when web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import base packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9779c",
   "metadata": {},
   "source": [
    "## Scraping data with `BeautifulSoup`\n",
    "\n",
    "### Importing `BeautifulSoup`\n",
    "\n",
    "In order to use `BeautifulSoup` we first need to make sure that we have it installed on our computer. Try to run the following code chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82194053",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this imports BeautifulSoup from its package, bs4\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f61184",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this to check your version\n",
    "## I wrote this notebook with version  4.12.2\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2da4d",
   "metadata": {},
   "source": [
    "If the above code does not work you will need to install the package before being able to run the code in this notebook. Here are installation instructions from the `bs4` documentation:\n",
    "- Via conda: <a href=\"https://anaconda.org/conda-forge/bs4\">https://anaconda.org/conda-forge/bs4</a>,\n",
    "- Via pip: <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83239b6",
   "metadata": {},
   "source": [
    "### The structure of an HTML page\n",
    "\n",
    "`BeautifulSoup` takes in an HTML document and will 'parse' it for you so that you can extract the information you want. To best understand what that means we will look at a toy example of a webpage. To see what the snippet of HTML code below looks like in a web browser click here <a href=\"SampleHTML.html\">SampleHTML.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is an html chunk\n",
    "## It has a head and a body, just like you\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f371b5",
   "metadata": {},
   "source": [
    "We can now use `BeautifulSoup` to parse this simple HTML chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we import the BeautifulSoup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we make a BeautifulSoup object out of the html code\n",
    "## The first input is the html code\n",
    "## The second input is how you want BeautifulSoup\n",
    "## to parse the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use the prettify method to make our html pretty and see what it has to say\n",
    "## Ideally this is how someone writing pure html code would write their code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dcc37",
   "metadata": {},
   "source": [
    "Html files have a natural tree structure that we will briefly cover now. Here is the tree of our sample HTML:\n",
    "\n",
    "<img src = \"lecture-2-assets/html_tree.png\" width = \"50%\"></img>\n",
    "\n",
    "Each level in the tree represents a 'generation' of the html code. for instance the body has 3 p children, the leftmost p has one b child. `BeautifulSoup` helps us traverse these trees to gather the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below are some examples of beautifulsoup methods and \n",
    "## attributes that help us better understand the structure \n",
    "## of html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can traverse to the \"title\" by working our way through\n",
    "## the tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notice we can also get the title like so\n",
    "## This is because this is the first and only title \n",
    "## in the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What if I just want the text from the title?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What html structure is the title's parent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a of the html document?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e49026",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a's class?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99b7b79b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a's class?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d1bd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple a's: can I find all of them?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8b9fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the first p of the document\n",
    "## What is the first p's class? \n",
    "## What string is in that p?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9477bbb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For all of the a's in the document find their href\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5254c9a",
   "metadata": {},
   "source": [
    "## Scraping real webpages\n",
    "\n",
    "Let's now pivot to a real webpage. In this example we will imagine we are in the spot of wanting to scrape information from our Erdős Institute I2I website here:  \n",
    "\n",
    "https://www.erdosinstitute.org/invitations-to-industry\n",
    "### Sending a request\n",
    "\n",
    "In order to scrape that data we need to have the HTML code associated with the page. In python we can do this with the `requests` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081861fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We send a request to the website's server with the following code, and store the response in the variable \"response\".\n",
    "\n",
    "response = requests.get(url=\"https://www.erdosinstitute.org/invitations-to-industry\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad412617",
   "metadata": {},
   "source": [
    "First we will note that, if the request was successful, we should be seeing `<Response [200]>` below. This tells us that the request was recieved and the data was returned successfully. If we instead saw something like `404` or `500`, we would know that something went wrong. For a list of possible response codes see <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d357ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response.status_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b318c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HTML code is stored in response.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now parse this data with BeautifulSoup\n",
    "soup = BeautifulSoup(response.content, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a997fcd",
   "metadata": {},
   "source": [
    "### Web developer tools\n",
    "\n",
    "As we can see, this is much messier than our simple example above. \n",
    "\n",
    "We want to find the names of the companies associated with each of the logos at the bottom of the page.\n",
    "\n",
    "To hone in on this information we can utilize the web developer tools for your browser.  These are generally found in dropdown menus from your browser.  For example, in chrome you can access it via View > Developer > Developer Tools.\n",
    "\n",
    "The web developer tools will allow you to find out where various components of the webpage live in the code. For example, you should be able to hover over an item on the webpage and it will highlight what HTML structure holds it.\n",
    "\n",
    "We can use this information to get the data we desire.\n",
    "\n",
    "Looking at one image and moving up the tree, we can see that all of the images are contained in the following div:\n",
    "\n",
    "```html\n",
    "<fluid-columns-repeater horizontal-gap=\"10\" vertical-gap=\"10\" justify-content=\"center\" direction=\"ltr\" container-id=\"comp-lr5r5app_wrapper\" items=\"54\" class=\"GPmm8Z\" role=\"list\" style>\n",
    "```\n",
    "\n",
    "Is this the only such div?  Let's check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Look for all divs with this class and container-id.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1044fa1a",
   "metadata": {},
   "source": [
    "There is only one.  Let's call it past_participants_container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb32bc48",
   "metadata": {},
   "outputs": [],
   "source": [
    "past_participants_container ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a63a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check it for all of the \"img\" tags."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44106dfb",
   "metadata": {},
   "source": [
    "The ones with \"img\" tags have the names of the presenters in the \"alt\" field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc7eff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a list comprehension to get all of the presenter names.\n",
    "\n",
    "presenter_names = \n",
    "\n",
    "print('There are',len(presenter_names), 'presenters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ffb881",
   "metadata": {},
   "source": [
    "We can also **try** to extract the list of url links to presenter companies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20818dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Attempt to extract all of the links using a list comprehension.\n",
    "\n",
    "presenter_links ="
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a711e8",
   "metadata": {},
   "source": [
    "Oh no!  What went wrong?  It looks like at least one of these presenters doesn't have an associated link.  Let's see if we can find out who it is using \"try/except\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fc559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in    :\n",
    "    try:\n",
    "        \n",
    "    except:\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99190f95",
   "metadata": {},
   "source": [
    "Only one presenter is missing a link.  That presenter is:  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda13f8",
   "metadata": {},
   "source": [
    "## Common problems while web scraping\n",
    "\n",
    "### Messy or inconsistent HTML code\n",
    "\n",
    "We have seen one problem that you can encounter while web scraping, small and messy differences in HTML code that make automating your scraping more difficult. It is important to note that 538 is actually not very messy in the grand scheme of the world wide web. For example, you can come across websites that do not label their HTML elements with `id`s or `class`es or any other kind of distinguishing meta data. This makes automation incredibly difficult. Other websites may offer no consistency from page to page. In such cases there may not be a quick or easy fix, you typically just have to hack something together and hope it works.\n",
    "\n",
    "### Too many requests\n",
    "\n",
    "Repeatedly sending requests to the same website can raise a flag at the site's server after which your IP address will be blocked from receiving future request results for some period of time. This is why it is good practice to space out your requests to a single website. You can do so with the `sleep` function in the `time` module, <a href=\"https://docs.python.org/3/library/time.html#time.sleep\">https://docs.python.org/3/library/time.html#time.sleep</a>. While this decreases your risk of being flagged as a bot/scraper, it is also just being a good denizen of the internet. Sending too many requests to a single website in a short amount of time can mess with that website's ability to function for other visitors.\n",
    "\n",
    "### Bot detection\n",
    "\n",
    "Some websites have been set up to detect bot/scraper activity regardless of the number of times you send a request. Sometimes there are ways around this, but the specific approach depends upon how the website is blocking your request. To counter such detection do a web search for the specific error or response code you are getting and look for a helpful stack overflow or stackexchange post.\n",
    "\n",
    "### User interactive content\n",
    "\n",
    "Some of the content on a page may be dependent on the actions of a user visiting that page. For example, there are websites where data tables do not load until the user has clicked a button or scrolled down the page.\n",
    "\n",
    "#### `selenium`\n",
    "\n",
    "One way to access information that requires user input is with `selenium`, <a href=\"https://www.selenium.dev/\">https://www.selenium.dev/</a>. `selenium` installation instructions can be found here, <a href=\"https://pypi.org/project/selenium/\">https://pypi.org/project/selenium/</a>, and documentation on how to use the package can be found here, <a href=\"https://selenium-python.readthedocs.io/index.html\">https://selenium-python.readthedocs.io/index.html</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b52dbb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we touched on how you can parse HTML code with the `bs4` package. We looked at both a simple phony example and an example from a live website. If you are interested in learning more about `bs4` I encourage you to consult their documentation, <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e3780",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023. Modified by Steven Gubkin 2024.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erdős Institute as subject to the license (see License.md)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
