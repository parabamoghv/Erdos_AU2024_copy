{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfacfff1",
   "metadata": {},
   "source": [
    "# Web Scraping with BeautifulSoup\n",
    "\n",
    "Sometimes there may not be an easily accessible data set for your project. However, there may be data that exists on the web which you can scrape. One way to do this in python is to use `BeautifulSoup`.\n",
    "\n",
    "## What we will accomplish in this notebook\n",
    "\n",
    "In this notebook we will:\n",
    "- Discuss the structure of HTML code,\n",
    "- Introduce the `bs4` pacakge,\n",
    "- Parse simple HTML code with `BeautifulSoup`,\n",
    "- Review how to request the HTML code from a url,\n",
    "- Scrape data from an actual webpage and\n",
    "- Touch on some of the issues that may arise when web scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f4760",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import base packages we'll use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f9779c",
   "metadata": {},
   "source": [
    "## Scraping data with `BeautifulSoup`\n",
    "\n",
    "### Importing `BeautifulSoup`\n",
    "\n",
    "In order to use `BeautifulSoup` we first need to make sure that we have it installed on our computer. Try to run the following code chunks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82194053",
   "metadata": {},
   "outputs": [],
   "source": [
    "## this imports BeautifulSoup from its package, bs4\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f61184",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this to check your version\n",
    "## I wrote this notebook with version  4.12.2\n",
    "print(bs4.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a2da4d",
   "metadata": {},
   "source": [
    "If the above code does not work you will need to install the package before being able to run the code in this notebook. Here are installation instructions from the `bs4` documentation:\n",
    "- Via conda: <a href=\"https://anaconda.org/conda-forge/bs4\">https://anaconda.org/conda-forge/bs4</a>,\n",
    "- Via pip: <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/#installing-beautiful-soup</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83239b6",
   "metadata": {},
   "source": [
    "### The structure of an HTML page\n",
    "\n",
    "`BeautifulSoup` takes in an HTML document and will 'parse' it for you so that you can extract the information you want. To best understand what that means we will look at a toy example of a webpage. To see what the snippet of HTML code below looks like in a web browser click here <a href=\"SampleHTML.html\">SampleHTML.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c55f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is an html chunk\n",
    "## It has a head and a body, just like you\n",
    "html_doc = \"\"\"\n",
    "<html><head><title>The Dormouse's story</title></head>\n",
    "<body>\n",
    "<p class=\"title\"><b>The Dormouse's story</b></p>\n",
    "\n",
    "<p class=\"story\">Once upon a time there were three little sisters; and their names were\n",
    "<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n",
    "<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n",
    "<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\n",
    "and they lived at the bottom of a well.</p>\n",
    "\n",
    "<p class=\"story\">...</p>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f371b5",
   "metadata": {},
   "source": [
    "We can now use `BeautifulSoup` to parse this simple HTML chunk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305e3a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## First we import the BeautifulSoup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadda44",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Now we make a BeautifulSoup object out of the html code\n",
    "## The first input is the html code\n",
    "## The second input is how you want BeautifulSoup\n",
    "## to parse the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea0fe84",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's use the prettify method to make our html pretty and see what it has to say\n",
    "## Ideally this is how someone writing pure html code would write their code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e52dcc37",
   "metadata": {},
   "source": [
    "Html files have a natural tree structure that we will briefly cover now. Here is the tree of our sample HTML:\n",
    "\n",
    "<img src = \"html_tree.png\" width = \"50%\"></img>\n",
    "\n",
    "Each level in the tree represents a 'generation' of the html code. for instance the body has 3 p children, the leftmost p has one b child. `BeautifulSoup` helps us traverse these trees to gather the data we want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2bc8c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Below are some examples of beautifulsoup methods and \n",
    "## attributes that help us better understand the structure \n",
    "## of html code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a435c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can traverse to the \"title\" by working our way through\n",
    "## the tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ff66eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Notice we can also get the title like so\n",
    "## This is because this is the first and only title \n",
    "## in the code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff74ec96",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What if I just want the text from the title?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9120fedf",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What html structure is the title's parent?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c2df9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a of the html document?\n",
    "soup.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e49026",
   "metadata": {},
   "outputs": [],
   "source": [
    "## What is the first a's class?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389e01e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## There are multiple a's can I find all of them?\n",
    "soup.find_all('a')\n",
    "\n",
    "\n",
    "# for a in soup.find_all('a'):\n",
    "#     print()\n",
    "#     print(a['class'], a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2bf7b99",
   "metadata": {},
   "source": [
    "#### Exercises\n",
    "\n",
    "Take a moment and try to complete the following exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b56e6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find the first p of the document\n",
    "## What is the first p's class? What string is in that p?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54200461",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For all of the a's in the document find their href\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a406bf7",
   "metadata": {},
   "source": [
    "## Scraping real webpages\n",
    "\n",
    "Let's now pivot to a real webpage. In this example we will imagine we are in the spot of wanting to scrape information regarding the website FiveThirtyEight's Sports articles as found here, <a href=\"https://fivethirtyeight.com/sports/\">https://fivethirtyeight.com/sports/</a>.\n",
    "\n",
    "### Sending a request\n",
    "\n",
    "In order to scrape that data we need to have the HTML code associated with the page. In python we can do this with the `requests` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5254c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081861fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is the url for the HTML code we want\n",
    "url = \"https://fivethirtyeight.com/sports/\"\n",
    "\n",
    "## We send a request to the website's server with\n",
    "## the following code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6b6285",
   "metadata": {},
   "source": [
    "Now we will want to store this response in a variable so we can access its contents. First we will note that, if the request was successful, we should be seeing `<Response [200]>` above. This tells us that the request was recieved and the data was returned successfully. If we instead saw something like `404` or `500`, we would know that something went wrong. For a list of possible response codes see <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses\">https://developer.mozilla.org/en-US/docs/Web/HTTP/Status#server_error_responses</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d357ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "r = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d84840",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b318c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The HTML code is stored in r.content\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efac2b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We can now parse this data with BeautifulSoup\n",
    "soup = BeautifulSoup(r.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ad3c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup.head.title"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0106d4aa",
   "metadata": {},
   "source": [
    "### Web developer tools\n",
    "\n",
    "As we can see, this is much messier than our simple example above. \n",
    "\n",
    "We only want three pieces of information for each article/podcast/posting listed on the page:\n",
    "1. The title,\n",
    "2. The author and\n",
    "3. The associated url.\n",
    "\n",
    "To hone in on this information we can utilize the web developer tools for your browser. Below are links on how to locate the web developer tools for Mozilla Firefox, Google Chrome and Safari:\n",
    "- Mozilla Firefox: Go to `Browser Tools` in the `Tools` dropdown menu and click on `Web Developer Tools` you should see something like this:\n",
    "<img src=\"firefox_develop.jpg\" width=\"80%\"></img>\n",
    "- Google Chrome: Go to `Developer` in the `View` dropdown menu and click on `Developer Tools` you should see something like this:\n",
    "<img src=\"chrome_develop.jpg\" width=\"80%\"></img>\n",
    "- Safari: Go to the `Develop` dropdown menu and select `Show Web Inspector`, if there is no `Develop` dropdown menu follow the instructions on this page <a href=\"https://support.apple.com/guide/safari/use-the-developer-tools-in-the-develop-menu-sfri20948/mac\">https://support.apple.com/guide/safari/use-the-developer-tools-in-the-develop-menu-sfri20948/mac</a>. You should see something like this once opened:\n",
    "<img src=\"safari_develop.jpg\" width=\"80%\"></img>\n",
    "\n",
    "<i>Note that the images above will be slightly different than what you see because 538 will have different articles at the time you access the page. These images were added 3-10-2022.</i>\n",
    "\n",
    "<br>\n",
    "\n",
    "The web developer tools will allow you to find out in what HTML elements certain pieces of data live. For example, you should be able to hover over an item on the webpage and it will highlight what HTML structure holds it. Here we can see what that looks like for the banner article (the large one at the top) of this page:\n",
    "<img src=\"div_highlight.png\" width=\"30%\"></img>\n",
    "\n",
    "We can use this information to get the data we desire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4ccfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Getting the articles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ea7fd0",
   "metadata": {},
   "source": [
    "##### Exercise\n",
    "\n",
    "Take some time to write code to retrieve all of the article authors below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee3370d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41314f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "## code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeda13f8",
   "metadata": {},
   "source": [
    "## Common problems while web scraping\n",
    "\n",
    "### Messy or inconsistent HTML code\n",
    "\n",
    "We have seen one problem that you can encounter while web scraping, small and messy differences in HTML code that make automating your scraping more difficult. It is important to note that 538 is actually not very messy in the grand scheme of the world wide web. For example, you can come across websites that do not label their HTML elements with `id`s or `class`es or any other kind of distinguishing meta data. This makes automation incredibly difficult. Other websites may offer no consistency from page to page. In such cases there may not be a quick or easy fix, you typically just have to hack something together and hope it works.\n",
    "\n",
    "### Too many requests\n",
    "\n",
    "Repeatedly sending requests to the same website can raise a flag at the site's server after which your IP address will be blocked from receiving future request results for some period of time. This is why it is good practice to space out your requests to a single website. You can do so with the `sleep` function in the `time` module, <a href=\"https://docs.python.org/3/library/time.html#time.sleep\">https://docs.python.org/3/library/time.html#time.sleep</a>. While this decreases your risk of being flagged as a bot/scraper, it is also just being a good denizen of the internet. Sending too many requests to a single website in a short amount of time can mess with that website's ability to function for other visitors.\n",
    "\n",
    "### Bot detection\n",
    "\n",
    "Some websites have been set up to detect bot/scraper activity regardless of the number of times you send a request. Sometimes there are ways around this, but the specific approach depends upon how the website is blocking your request. To counter such detection do a web search for the specific error or response code you are getting and look for a helpful stack overflow or stackexchange post.\n",
    "\n",
    "### User interactive content\n",
    "\n",
    "Some of the content on a page may be dependent on the actions of a user visiting that page. For example, there are websites where data tables do not load until the user has clicked a button or scrolled down the page.\n",
    "\n",
    "#### `selenium`\n",
    "\n",
    "One way to access information that requires user input is with `selenium`, <a href=\"https://www.selenium.dev/\">https://www.selenium.dev/</a>. `selenium` installation instructions can be found here, <a href=\"https://pypi.org/project/selenium/\">https://pypi.org/project/selenium/</a>, and documentation on how to use the package can be found here, <a href=\"https://selenium-python.readthedocs.io/index.html\">https://selenium-python.readthedocs.io/index.html</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33b52dbb",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this notebook we touched on how you can parse HTML code with the `bs4` package. We looked at both a simple phony example and an example from a live website. If you are interested in learning more about `bs4` I encourage you to consult their documentation, <a href=\"https://www.crummy.com/software/BeautifulSoup/bs4/doc/\">https://www.crummy.com/software/BeautifulSoup/bs4/doc/</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a01e3780",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ed0b0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
