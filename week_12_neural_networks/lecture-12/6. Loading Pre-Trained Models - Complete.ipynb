{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa7277b",
   "metadata": {},
   "source": [
    "# Loading Pre-Trained Models\n",
    "\n",
    "Real world neural net models can take a long long long time to train. It is thus standard to save these models once they are fit and then load the fitted model at a later time.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Cover how to load a saved neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932035cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## For data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "## For plotting\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "\n",
    "## This sets the plot style\n",
    "## to have a grid on a white background\n",
    "set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e170d9",
   "metadata": {},
   "source": [
    "## `keras` and `load_model`\n",
    "\n",
    "In the previous notebook we trained a recurrent neural network (RNN) to predict the sentiment of an IMDB movie review. This model did not take a long time to train, but many real-world models take a very long time to train. For example, the popular `Word2Vec` word embedding network took about a day to train.\n",
    "\n",
    "Such models are saved when the training step is complete and then they are reloaded anytime you want to use them.\n",
    "\n",
    "In `keras` a saved model can be loaded with `load_model`. Let's demonstrate this with the IMDB data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "521a35c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## The data is stored in here\n",
    "from keras.datasets import imdb\n",
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df6bc80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This will determine the number of vocab words in our\n",
    "## dictionary\n",
    "max_features = 10000\n",
    "\n",
    "## num_words tells keras to return the reviews so they contain only\n",
    "## the num_words most used words across all the reviews\n",
    "(X_train, y_train), (X_test,y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "## Note expect to receive a warning, this is not your fault, and is due to how\n",
    "## keras is loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ff2a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 100\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f88c502",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import load_model from keras.models\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f1fb30",
   "metadata": {},
   "source": [
    "To load a saved model we just have to call `load_model` with the file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b55f4ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## call load_model(filename)\n",
    "model = load_model(\"lecture-12-assets/RNN_saved_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adeb938",
   "metadata": {},
   "source": [
    "Now the trained model is loaded and we can use it to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09a1f6e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 63ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-09 14:35:36.444219: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[4.1888725e-05]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train[71,:].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a317026d",
   "metadata": {},
   "source": [
    "Or we can look at the weights of the trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "767676f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-0.00985114, -0.11436401,  0.02277907, ..., -0.01103386,\n",
       "         -0.01198885, -0.1777059 ],\n",
       "        [ 0.00239407, -0.00309459,  0.0312617 , ...,  0.08563068,\n",
       "          0.04792159, -0.06987754],\n",
       "        [ 0.0073409 , -0.02245055,  0.00177751, ..., -0.03965121,\n",
       "          0.01927148,  0.03144506],\n",
       "        ...,\n",
       "        [ 0.01877508, -0.02455333, -0.01819628, ...,  0.01391079,\n",
       "         -0.04324719,  0.08056263],\n",
       "        [ 0.03281326, -0.02178513, -0.05088637, ...,  0.05765755,\n",
       "          0.01174881, -0.0296497 ],\n",
       "        [-0.01994938, -0.04241132,  0.02100001, ..., -0.05941164,\n",
       "         -0.08499762,  0.00625301]], dtype=float32),\n",
       " array([[ 0.25986657,  0.38435927, -0.16445915, ...,  0.14844938,\n",
       "         -0.05289856, -0.29928198],\n",
       "        [ 0.1703746 , -0.07275026, -0.19801772, ..., -0.06672079,\n",
       "         -0.16792029, -0.21507718],\n",
       "        [-0.0029123 ,  0.24266644, -0.32251298, ..., -0.22634356,\n",
       "         -0.02428091, -0.17713459],\n",
       "        ...,\n",
       "        [ 0.3193842 ,  0.19623877,  0.2466797 , ...,  0.00689747,\n",
       "          0.00510913,  0.12005606],\n",
       "        [-0.18298386, -0.16676204, -0.26066148, ..., -0.05072746,\n",
       "          0.4106726 , -0.2473272 ],\n",
       "        [ 0.25961316,  0.15390153, -0.46090862, ..., -0.18029056,\n",
       "         -0.21409568,  0.25945637]], dtype=float32),\n",
       " array([[-0.0900596 ,  0.10695183,  0.20242192, ..., -0.22088796,\n",
       "          0.2765918 , -0.44599262],\n",
       "        [-0.24820928,  0.05865033, -0.03592983, ..., -0.07598688,\n",
       "          0.2521107 ,  0.25136414],\n",
       "        [ 0.05509364, -0.05574482, -0.07391478, ...,  0.07272828,\n",
       "         -0.05668626, -0.3147238 ],\n",
       "        ...,\n",
       "        [ 0.16383909, -0.05673456, -0.04989555, ..., -0.34672725,\n",
       "          0.28904054,  0.24385035],\n",
       "        [ 0.09181154, -0.06642541,  0.28415695, ..., -0.05680364,\n",
       "         -0.03439362,  0.06969928],\n",
       "        [-0.06862794, -0.15103005,  0.05043206, ..., -0.05588737,\n",
       "          0.03532048,  0.03498079]], dtype=float32),\n",
       " array([ 0.01293383, -0.00069818,  0.00155681, -0.00042199, -0.00337094,\n",
       "        -0.00166222, -0.00703995, -0.00172855,  0.01176263, -0.009681  ,\n",
       "        -0.00057685,  0.00707125,  0.0028705 , -0.00032439, -0.00820244,\n",
       "        -0.00397017, -0.00046399, -0.00032409,  0.00247007, -0.00317327,\n",
       "        -0.00297835, -0.00434288, -0.00133575, -0.00241383, -0.00786237,\n",
       "        -0.01089945,  0.00295317, -0.00253365, -0.00224272,  0.00114163,\n",
       "         0.00092558,  0.00254263], dtype=float32),\n",
       " array([[-1.1311382 ],\n",
       "        [ 0.04860278],\n",
       "        [ 1.1727622 ],\n",
       "        [ 0.47586456],\n",
       "        [-1.3099477 ],\n",
       "        [ 0.54984015],\n",
       "        [ 1.2168145 ],\n",
       "        [-0.7784451 ],\n",
       "        [ 1.2193573 ],\n",
       "        [ 0.6286639 ],\n",
       "        [-0.90260434],\n",
       "        [ 1.0648024 ],\n",
       "        [-0.71431315],\n",
       "        [-0.77084756],\n",
       "        [-0.19980672],\n",
       "        [-0.2672595 ],\n",
       "        [-0.53091973],\n",
       "        [-0.5774656 ],\n",
       "        [-0.60633594],\n",
       "        [ 1.2046282 ],\n",
       "        [ 1.3873727 ],\n",
       "        [ 0.17703198],\n",
       "        [ 0.87374336],\n",
       "        [ 0.11093862],\n",
       "        [-1.0734128 ],\n",
       "        [ 1.1732452 ],\n",
       "        [ 1.2436273 ],\n",
       "        [ 0.25031915],\n",
       "        [ 1.2506835 ],\n",
       "        [ 1.3254514 ],\n",
       "        [-0.47261196],\n",
       "        [ 0.68154645]], dtype=float32),\n",
       " array([-0.03948984], dtype=float32)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## .get_weights()\n",
    "## returns the weights of your model\n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1422e3ad",
   "metadata": {},
   "source": [
    "If we wanted to we could also train the model for additional epochs or perform any other kind of manipulations in which we may be interested."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ef56c4",
   "metadata": {},
   "source": [
    "## Model packages\n",
    "\n",
    "Sometimes pre-trained models will be important enough that they have their own separate python packages. For example, `gensim` for `Word2Vec` <a href=\"https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py\">https://radimrehurek.com/gensim/auto_examples/tutorials/run_word2vec.html#sphx-glr-auto-examples-tutorials-run-word2vec-py</a> and `Hugging Face` for `BERT` <a href=\"https://huggingface.co/\">https://huggingface.co/</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65a444a0",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5962a59c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
