{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59eb75f9",
   "metadata": {},
   "source": [
    "# Categorical Variables and Interactions\n",
    "\n",
    "We continue our work with multiple linear regression by showing how to include categorical variables and interaction terms into your regression model.\n",
    "\n",
    "## What we will accomplish\n",
    "\n",
    "We will:\n",
    "- Introduce a data set on beer,\n",
    "- Show how to incorporate categorical variables into multiple linear regression,\n",
    "- Demonstrate one-hot encoding in python and\n",
    "- Discuss interaction terms and how they affect your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69abccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import some packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8dbb5b9",
   "metadata": {},
   "source": [
    "## A beers data set\n",
    "\n",
    "Let us start by loading in a new data set, `beer1.csv`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8503d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the data\n",
    "## note you may need to change the path if you\n",
    "## are running Windows\n",
    "beer = pd.read_csv(\"../../../data/beer1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fedb1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the train test split\n",
    "## ignore stratify for now, you will have a problem\n",
    "## session question about it\n",
    "beer_train, beer_test = train_test_split(beer.copy(), \n",
    "                                            shuffle=True,\n",
    "                                            random_state=614,\n",
    "                                            stratify=beer['Beer_Type'],\n",
    "                                            test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bd940",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_train.sample(5, random_state=440)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab82f59",
   "metadata": {},
   "source": [
    "As we can see, this data set contains information on various beers. It includes the beer's `IBU` (international bitterness units), `ABV` (alcohol by volume), user `Rating` and the type of the beer. In this notebook we will focus on building models to predict the beer's `IBU`. It's reasonable to assume that `Rating` has no bearing on the `IBU` value for a particular beer, same for the name. So moving forward we will focus on the `ABV` and `Beer_Type` as potential features.\n",
    "\n",
    "Let's look at any potential relationship between `IBU` and `ABV`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df10cb27",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(beer_train.ABV,\n",
    "               beer_train.IBU)\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53112be",
   "metadata": {},
   "source": [
    "There appears to be positive linear relationship between `ABV` and `IBU`. Our first two models will thus be the simple baseline and a simple linear regression regressing `IBU` on `ABV`.\n",
    "\n",
    "##### Baseline model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = E(\\text{IBU}) + \\epsilon\n",
    "$$\n",
    "\n",
    "##### Simple linear regression model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\epsilon\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e290210e",
   "metadata": {},
   "source": [
    "## Categorical variables\n",
    "\n",
    "Now let's investigate if `Beer_Type` seems to have any impact on `IBU`. One way to do this is to look at some plots.\n",
    "\n",
    "A nice plot to use is `seaborn`'s `swarmplot`, <a href=\"https://seaborn.pydata.org/generated/seaborn.swarmplot.html\">https://seaborn.pydata.org/generated/seaborn.swarmplot.html</a>. This plots each observation as a dot according to the value it has for the desired feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf08640",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a figure object\n",
    "plt.figure(figsize=(4,6))\n",
    "\n",
    "## Call swarmplot\n",
    "## First put in the dataframe in data = \n",
    "## Then what you want on the x and y axis\n",
    "## Finally, palette, an optional input, allows me to color the points\n",
    "sns.swarmplot(data=beer_train,\n",
    "               x = 'Beer_Type',\n",
    "               y = 'IBU',\n",
    "            hue='Beer_Type',\n",
    "            palette=['blue', 'orange'],\n",
    "            legend=False)\n",
    "\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xlabel(\"Beer Type\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff78e923",
   "metadata": {},
   "source": [
    "If possible, we can also recreate the scatter plot from before, this time colored by category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b688bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='IPA'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='IPA'].IBU,\n",
    "               label=\"IPAs\",\n",
    "               marker='v',\n",
    "               s=60,\n",
    "               edgecolor='black',\n",
    "               c='orange')\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='Stout'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='Stout'].IBU,\n",
    "               label=\"Stout\",\n",
    "               s=60,\n",
    "               edgecolor='black',\n",
    "               c='lightblue')\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca17fab3",
   "metadata": {},
   "source": [
    "In both plots there seems reason to believe that IPAs tent to have slightly higher IBUs than Stouts. Let's see how to encode this information to be used in multiple linear regression model.\n",
    "\n",
    "### One-hot encoding\n",
    "\n",
    "Currently our `Beer_Type` column is stored as a column of strings. This is great for human readability, but terrible for regression models, enter <i>one-hot encoding</i>.\n",
    "\n",
    "One-hot encoding is when you take a categorical variable and represent it as a collection of new $0-1$ variables. Suppose you have a variable, $x$, with $k$ unique categories, then one-hot encoding is the process of creating $k-1$ indicator variables:\n",
    "\n",
    "$$\n",
    "1_j = \\left\\lbrace \\begin{array}{l l} 1 & \\text{if } x=j \\\\ 0 & \\text{if } x \\neq j\\end{array} \\right., \\text{ for } j = 1, \\dots, k-1.\n",
    "$$\n",
    "\n",
    "We only need $k-1$ of these variables because of the process of elimination. If all of the $1_j=0$, then that means that $x$ is not any of $1,\\dots,k-1$ and thus it must be $k$.\n",
    "\n",
    "#### In python\n",
    "\n",
    "Let's now demonstrate how to do this in python. We will make an indicator for when a beer is a Stout, i.e.\n",
    "\n",
    "$$\n",
    "1_{\\text{Stout}} = \\left\\lbrace \\begin{array}{l l} 1 & \\text{if the beer is a Stout}  \\\\ 0 & \\text{Else} \\end{array} \\right..\n",
    "$$\n",
    "\n",
    "Since there are only two possible values we could do this by hand, but we will demonstrate a function that is useful for variables with more than two categories, `get_dummies`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html\">https://pandas.pydata.org/docs/reference/api/pandas.get_dummies.html</a>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a8e85a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrate it here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfc24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Store the variable in beer_train here\n",
    "beer_train.loc[:,'Stout'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eefe95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "beer_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44ba81b",
   "metadata": {},
   "source": [
    "This new indicator variable allows us to fit a third model.\n",
    "\n",
    "##### Stout model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\beta_2 \\text{Stout} + \\epsilon\n",
    "$$\n",
    "\n",
    "Let's quickly fit this model and plot it along with our training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce20738",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the model object\n",
    "stout_lr = LinearRegression(copy_X = True)\n",
    "\n",
    "## Fit the model\n",
    "stout_lr.fit(beer_train[['ABV', 'Stout']].values,\n",
    "                beer_train['IBU'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b228345a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code plots that model with the training data ##\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='IPA'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='IPA'].IBU,\n",
    "               label=\"IPAs\",\n",
    "               marker='v',\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='orange')\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='Stout'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='Stout'].IBU,\n",
    "               label=\"Stout\",\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='lightblue')\n",
    "\n",
    "xs_ipa = np.zeros((1000,2))\n",
    "xs_ipa[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "ipa_line = stout_lr.predict(xs_ipa)\n",
    "\n",
    "xs_stout = np.ones((1000,2))\n",
    "xs_stout[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "stout_line = stout_lr.predict(xs_stout)\n",
    "\n",
    "\n",
    "plt.plot(xs_ipa[:,0], ipa_line,\n",
    "            '--', \n",
    "            c='orange',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for IPAs\")\n",
    "plt.plot(xs_stout[:,0], stout_line,\n",
    "            '-', \n",
    "            c='blue',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for Stouts\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4084048",
   "metadata": {},
   "source": [
    "## Interaction terms\n",
    "\n",
    "You may notice that the model we just fit produces lines with the same slope for IPAs and Stouts. If we return to the model itself we can see why:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\beta_2 \\text{Stout} + \\epsilon\n",
    "$$\n",
    "\n",
    "When $\\text{Stout}=0$ we have that:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\epsilon,\n",
    "$$\n",
    "\n",
    "however when $\\text{Stout}=1$ we have:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = (\\beta_0 + \\beta_2) + \\beta_1 \\text{ABV} + \\epsilon.\n",
    "$$\n",
    "\n",
    "We can notice that all that changed for this model was the intercept of the line, not the slope. In order to impact the slope, we must add an <i>interaction term</i> between `ABV` and `Stout`.\n",
    "\n",
    "Interaction terms are just a fancy way of saying we should multiply two variables. So here we want to multiply the `ABV` and the `Stout` column. This produces the following interaction model (our final model for this notebook):\n",
    "\n",
    "##### Interaction Model\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\beta_2 \\text{Stout} + \\beta_3 \\text{ABV} \\times \\text{Stout} + \\epsilon\n",
    "$$\n",
    "\n",
    "We can once again observe the differences for $\\text{Stout} = 0$ vs $\\text{Stout} = 1$.\n",
    "\n",
    "When $\\text{Stout}=0$ we have that:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = \\beta_0 + \\beta_1 \\text{ABV} + \\epsilon,\n",
    "$$\n",
    "\n",
    "however when $\\text{Stout}=1$ we have:\n",
    "\n",
    "$$\n",
    "\\text{IBU} = (\\beta_0 + \\beta_2) + (\\beta_1 + \\beta_3) \\text{ABV} + \\epsilon.\n",
    "$$\n",
    "\n",
    "This gives both a potentially different intercept <i>and</i> slope for the regression line.\n",
    "\n",
    "Let's visualize this quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f56c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the interaction term\n",
    "beer_train['ABV_Stout'] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55837cd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the model object\n",
    "interaction_lr = LinearRegression(copy_X = True)\n",
    "\n",
    "## Fit the model\n",
    "interaction_lr.fit(beer_train[['ABV', 'Stout', 'ABV_Stout']].values,\n",
    "                        beer_train['IBU'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db2e522",
   "metadata": {},
   "outputs": [],
   "source": [
    "## This code plots that model with the training data ##\n",
    "\n",
    "plt.figure(figsize=(9,6))\n",
    "\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='IPA'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='IPA'].IBU,\n",
    "               label=\"IPAs\",\n",
    "               marker='v',\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='orange')\n",
    "plt.scatter(beer_train.loc[beer_train.Beer_Type=='Stout'].ABV,\n",
    "               beer_train.loc[beer_train.Beer_Type=='Stout'].IBU,\n",
    "               label=\"Stout\",\n",
    "               s=60,\n",
    "               alpha=.5,\n",
    "               edgecolor='black',\n",
    "               c='lightblue')\n",
    "xs_ipa = np.zeros((1000,3))\n",
    "xs_ipa[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "xs_ipa[:,2] = xs_ipa[:,0]*xs_ipa[:,1]\n",
    "ipa_line = interaction_lr.predict(xs_ipa)\n",
    "\n",
    "xs_stout = np.ones((1000,3))\n",
    "xs_stout[:,0] = np.linspace(beer_train.ABV.min()-2,\n",
    "                    beer_train.ABV.max()+2,1000)\n",
    "xs_stout[:,2] = xs_stout[:,0]*xs_stout[:,1]\n",
    "stout_line = interaction_lr.predict(xs_stout)\n",
    "\n",
    "\n",
    "plt.plot(xs_ipa[:,0], ipa_line,\n",
    "            '--', \n",
    "            c='orange',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for IPAs\")\n",
    "plt.plot(xs_stout[:,0], stout_line,\n",
    "            '-', \n",
    "            c='blue',\n",
    "            linewidth=1.5,\n",
    "            label=\"Model Output for Stouts\")\n",
    "\n",
    "\n",
    "plt.xlabel(\"ABV\", fontsize=12)\n",
    "plt.ylabel(\"IBU\", fontsize=12)\n",
    "plt.xticks(fontsize=10)\n",
    "plt.yticks(fontsize=10)\n",
    "plt.legend(fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0324c29d",
   "metadata": {},
   "source": [
    "This looks like a better fit on the training data. But let's use cross-validation to see which of our four proposed models is best.\n",
    "\n",
    "### Comparing all four models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9bf3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## import KFold\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "## import mean_squared_error\n",
    "from sklearn.metrics import mean_squared_error as mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac581250",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make the KFold object\n",
    "kfold = KFold(n_splits=5,\n",
    "                 shuffle=True,\n",
    "                 random_state=431)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41fb1097",
   "metadata": {},
   "outputs": [],
   "source": [
    "mses = np.zeros((4, 5))\n",
    "\n",
    "## This will keep track of the split we are on\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(beer_train):\n",
    "    beer_tt = beer_train.iloc[train_index]\n",
    "    beer_ho = beer_train.iloc[test_index]\n",
    "    \n",
    "    ## baseline model\n",
    "    pred_baseline = beer_tt.IBU.mean()*np.ones(len(beer_ho))\n",
    "    \n",
    "    ## SLR model\n",
    "    slr = LinearRegression(copy_X=True)\n",
    "    slr.fit(beer_tt.ABV.values.reshape(-1,1),\n",
    "               beer_tt.IBU.values)\n",
    "    pred_slr = slr.predict(beer_ho.ABV.values.reshape(-1,1))\n",
    "    \n",
    "    \n",
    "    ## STOUT Model\n",
    "    stout_model = LinearRegression(copy_X=True)\n",
    "    stout_model.fit(beer_tt[['ABV', 'Stout']].values,\n",
    "                 beer_tt.IBU.values)\n",
    "    pred_stout = stout_model.predict(beer_ho[['ABV', 'Stout']].values)\n",
    "    \n",
    "    ## Interaction Model\n",
    "    interact_model = LinearRegression(copy_X=True)\n",
    "    interact_model.fit(beer_tt[['ABV', 'Stout', 'ABV_Stout']].values,\n",
    "                       beer_tt.IBU.values)\n",
    "    pred_interact = interact_model.predict(beer_ho[['ABV', 'Stout', 'ABV_Stout']].values)\n",
    "    \n",
    "    ### record MSEs ###\n",
    "    mses[0,i] = mse(beer_ho.IBU.values, pred_baseline)\n",
    "    mses[1,i] = mse(beer_ho.IBU.values, pred_slr)\n",
    "    mses[2,i] = mse(beer_ho.IBU.values, pred_stout)\n",
    "    mses[3,i] = mse(beer_ho.IBU.values, pred_interact)\n",
    "\n",
    "    ## increase the counter\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb6c4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Print the results\n",
    "print(\"The average cross-validation mse for the baseline model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[0],4))\n",
    "print(\"The average cross-validation mse for the simple linear regression model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[1],4))\n",
    "print(\"The average cross-validation mse for the Stout model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[2],4))\n",
    "print(\"The average cross-validation mse for the interaction model is\",\n",
    "                      np.round(np.mean(mses, axis=1)[3],4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "943fea0b",
   "metadata": {},
   "source": [
    "The interaction model appears to have the best cross-validation performance (although the Stout model will likely give similar performance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed58e82",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b45312",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
