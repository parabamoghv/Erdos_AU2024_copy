{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e73ab097",
   "metadata": {},
   "source": [
    "# Problem Session 3\n",
    "\n",
    "## More Regression\n",
    "\n",
    "The problems in this notebook will cover the content covered in our Regression lectures including:\n",
    "- Multiple Linear Regression\n",
    "- kNN Regression\n",
    "- Categorical Variables and Interactions\n",
    "- Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c455cc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## We first load in packages we will need\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff585fa7",
   "metadata": {},
   "source": [
    "#### 1. Preparing the data\n",
    "\n",
    "In this notebook you will continue to model the median selling price we started in the last problem session. First we have to load the data and repeat some of the cleaning we did in `Problem Session 2`.\n",
    "\n",
    "##### a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "279b0e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try to recall how to load the data without peaking\n",
    "housing = \n",
    "\n",
    "# drop the rows with null values\n",
    "housing = \n",
    "\n",
    "def clean_column(text:str) -> float:\n",
    "    text = text[1:] # removes leading $\n",
    "    return float(text.replace(',','')) # removes comma and converts to float\n",
    "\n",
    "# apply clean_column to the median house value.\n",
    "housing.median_house_value = \n",
    "\n",
    "housing.info()\n",
    "\n",
    "assert(housing.shape[0] == 20433)\n",
    "assert(housing.median_house_value.dtype == float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be65df52",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Make the train test split using `sklearn`'s `train_test_split`.  Use an 80/20 split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44232cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train, housing_test = \n",
    "\n",
    "assert(housing_train.shape[0] == int(housing.shape[0]*0.8))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db518361",
   "metadata": {},
   "source": [
    "Remember that the data was truncated at an upper limit of $\\$500000$ for the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c08ad7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set aside all of the rows for which the median house value is 500000\n",
    "housing_truncated = housing[housing.median_house_value == 500000]\n",
    "housing_train_truncated = housing_train[housing_train.median_house_value == 500000]\n",
    "housing_test_truncated = housing_test[housing_test.median_house_value == 500000]\n",
    "\n",
    "# Redefine these to only include the non-truncated examples\n",
    "housing = housing[housing.median_house_value < 500000]\n",
    "housing_train = housing_train[housing_train.median_house_value < 500000]\n",
    "housing_test= housing_test[housing_test.median_house_value < 500000]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e142f89",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "If you need to, take a moment to refresh yourself on these data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29eb9ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d47521a",
   "metadata": {},
   "source": [
    "#### 2. More EDA\n",
    "\n",
    "In `Problem Session 2` you examined potential linear relationships with `median_house_value` and:\n",
    "- `median_income`,\n",
    "- `households`\n",
    "\n",
    "In this notebook we will do a little feature engineering and also use the `ocean_proximity` categorical variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a3d811",
   "metadata": {},
   "source": [
    "##### a. \n",
    "\n",
    "One way to examine if a categorical variable has an impact on an outcome variable is to compare the mean or median of the outcome variable among the different categories.\n",
    "\n",
    "Use `pandas` `groupby`, <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html\">https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.groupby.html</a>, to examine the mean  `median_house_value` by the value of `ocean_proximity`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d19868",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035e1002",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean by 'ocean_proximity'\")\n",
    "print(\"=====================\")\n",
    "print(housing_train.groupby('ocean_proximity').median_house_value.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6702cd",
   "metadata": {},
   "source": [
    "##### b.\n",
    "\n",
    "Another way to investigate the potential impact of categorical variables is to make plots examining the distribution of the outcome variable for each different category. \n",
    "\n",
    "Two common plots that are considered are box and whisker plots and violin plots. These can be made quickly using `seaborn`'s `boxplot`, <a href=\"https://seaborn.pydata.org/generated/seaborn.boxplot.html\">https://seaborn.pydata.org/generated/seaborn.boxplot.html/</a>, and `violinplot`, <a href=\"https://seaborn.pydata.org/generated/seaborn.violinplot.html\">https://seaborn.pydata.org/generated/seaborn.violinplot.html</a> functions.\n",
    "\n",
    "Below we will look at the distribution of `median_house_income` by `ocean_proximity` using both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fdc1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Boxplot for fuel\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "sns.boxplot(data = housing_train,\n",
    "               y = 'median_house_value',\n",
    "               x = 'ocean_proximity')\n",
    "\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Median House Value\", fontsize=12)\n",
    "plt.xlabel(\"Ocean Proximity\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c82597e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## violinplot for fuel\n",
    "plt.figure(figsize=(6,5))\n",
    "\n",
    "sns.violinplot(data = housing_train,\n",
    "               y = 'median_house_value',\n",
    "               x = 'ocean_proximity')\n",
    "\n",
    "plt.yticks(fontsize=10)\n",
    "plt.xticks(fontsize=10)\n",
    "\n",
    "plt.ylabel(\"Median House Value\", fontsize=12)\n",
    "plt.xlabel(\"Ocean Proximity\", fontsize=12)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c042de",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Discuss any thoughts you have about the `ocean_proximity` variable here.  Will you use all levels?  Will you combine some levels?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f766f2",
   "metadata": {},
   "source": [
    "##### d.\n",
    "\n",
    "From your investigations above you likely noticed that `INLAND` seems like a relevant predictor.\n",
    "\n",
    "Create a new column in the data set called `INLAND` that is `1` if the `ocean_type` is `INLAND` and `0` otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec34fc7",
   "metadata": {},
   "source": [
    "##### Sample Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34327717",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26a76e94",
   "metadata": {},
   "source": [
    "e. \n",
    "\n",
    "Rather than regressing on the total number of rooms, it seems a bit more sensible to use average number of rooms per household.  Create a new feature called `rooms_per_household`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83e1fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train['rooms_per_household'] = "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4635a669",
   "metadata": {},
   "source": [
    "#### 4. Comparing models\n",
    "\n",
    "##### a.\n",
    "\n",
    "Use cross validation to compare the following models:\n",
    "\n",
    "* A simple linear regression on `median_income`\n",
    "* A multiple linear regression using all of the features\n",
    "* A kNN model using all of the features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90aa5138",
   "metadata": {},
   "source": [
    "##### b. \n",
    "\n",
    "Create a pipeline for a kNN model.  It should first standardize the features and then train a kNN model with $k=10$ on those standardized features.  Train the model on the first $80\\%$ of the training data and evaluate it on the rest.\n",
    "\n",
    "We are doing this before cross-validation for pedagogical reasons:  probably the first time you write a pipeline should not be inside a loop where it is a little harder to debug."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3900d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "housing_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ab3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms',\n",
    "       'total_bedrooms', 'population', 'households', 'median_income', 'INLAND',\n",
    "       'rooms_per_household']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import \n",
    "from sklearn.preprocessing import \n",
    "from sklearn.neighbors import \n",
    "from sklearn.metrics import \n",
    "\n",
    "knn = \n",
    "\n",
    "#housing_tt is the first 80% of the rows, housing_val is the last 80% of the rows\n",
    "housing_tt = \n",
    "housing_val = \n",
    "\n",
    "\n",
    "val_predictions =\n",
    "val_rmse = \n",
    "print(val_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dcfe93",
   "metadata": {},
   "source": [
    "##### c.\n",
    "\n",
    "Perform 5-fold cross-validation to compare all of the models from 4a."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0e4b38",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import \n",
    "from sklearn.linear_model import "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea1203",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a KFold object\n",
    "## remember to set a random_state and set shuffle = True\n",
    "num_splits = 5\n",
    "num_models = 3\n",
    "kfold = KFold(num_splits,\n",
    "              random_state = 216,\n",
    "              shuffle=True)\n",
    "\n",
    "\n",
    "## This array will hold the mse for each model and split\n",
    "rmses = np.zeros((num_models, num_splits))\n",
    "\n",
    "## sets a split counter\n",
    "i = 0\n",
    "\n",
    "## loop through the kfold here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c74d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses.mean(axis = 1), rmses.std(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6ec597c",
   "metadata": {},
   "source": [
    "Compare/Contrast the performance of these models.  How did they compare with the models from last week?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ec99e2",
   "metadata": {},
   "source": [
    "##### Sample Solution\n",
    "\n",
    "Of these 3 models, kNN has the lowest cross validation RMSE.  However, the performance of the kNN using all features is worse than when we only used lat/lon last week!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea85650",
   "metadata": {},
   "source": [
    "### BONUS\n",
    "\n",
    "If you somehow still have time to work on a bonus activity, try this!\n",
    "\n",
    "Fill in the blanks for the class called `KNN_then_Linear` below which first fits a KNN model to one subset of the features and then fits a linear model to the residuals of the KNN model using another subset of the features.\n",
    "\n",
    "This is a simple example of a strategy called \"boosting\" which we will cover in more depth later.\n",
    "\n",
    "What is the cross validation rmse of this model when we use lat/lon for the KNN features and median income and INLAND for the linear feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb60e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN_then_Linear():\n",
    "    def __init__(self, knn_features, linear_features, n_neighbors = 10):\n",
    "        '''\n",
    "        knn_features: A list of feature names for knn\n",
    "        linear_features: A list of feature names for linear regression on the residuals of the knn model\n",
    "        n_neighbors: The number of neighbors used by knn\n",
    "        '''\n",
    "        self.knn = None\n",
    "        self.linear = None\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.knn_features = knn_features\n",
    "        self.linear_features = linear_features\n",
    "    def fit(self,X,y):\n",
    "        '''\n",
    "        X:  A pandas dataframe.  It must have all features in knn_features and linear_features\n",
    "        y:  A pandas series.\n",
    "        '''\n",
    "        # Instantiate knn model object\n",
    "        self.knn = \n",
    "        # Fit self.knn\n",
    "\n",
    "        # Get the predictions\n",
    "        predictions = \n",
    "\n",
    "        # Get the residuals\n",
    "        residuals = \n",
    "\n",
    "        # Instantiate the linear regression model object\n",
    "        self.linear = \n",
    "\n",
    "        # Fit self.linear using the residuals as targets.\n",
    "    def predict(self,X):\n",
    "        '''\n",
    "        X:  A pandas dataframe.  It must have all features in knn_features and linear_features\n",
    "        returns: the prediction of the model on X\n",
    "        '''\n",
    "        # Should return the sum of the predictions from self.knn and self.linear\n",
    "        return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e310dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_splits = 5\n",
    "kfold = KFold(num_splits,\n",
    "              random_state = 216,\n",
    "              shuffle=True)\n",
    "\n",
    "rmses_ktl = np.zeros(num_splits)\n",
    "\n",
    "i=0\n",
    "for train_index, test_index in kfold.split(housing_train):\n",
    "    ## cv training set\n",
    "    housing_tt = housing_train.iloc[train_index]\n",
    "    \n",
    "    ## cv holdout set\n",
    "    housing_ho = housing_train.iloc[test_index]\n",
    "      \n",
    "    ## Fit and get ho mse for mlr model\n",
    "    ktl = KNN_then_Linear(knn_features=['latitude','longitude'], linear_features=['median_income', 'INLAND'])\n",
    "    \n",
    "    ktl.fit(housing_tt[['latitude','longitude', 'median_income', 'INLAND']], housing_tt.median_house_value)    \n",
    "    rmses_ktl[i] = root_mean_squared_error(housing_ho.median_house_value, ktl.predict(housing_ho[['latitude','longitude', 'median_income', 'INLAND']]))\n",
    "    i = i + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2953f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmses_ktl.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243026ee",
   "metadata": {},
   "source": [
    "Our best performing model yet!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81205ab9",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd≈ës Institute Data Science Boot Camp by Steven Gubkin.\n",
    "\n",
    "Please refer to the license in this repo for information on redistribution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
