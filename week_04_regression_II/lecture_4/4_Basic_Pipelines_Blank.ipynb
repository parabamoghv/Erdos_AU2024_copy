{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Pipelines\n",
    "\n",
    "Put on your Super Mariio hats because we are going to dive into some pipelines!\n",
    "\n",
    "## What will we accomplish\n",
    "\n",
    "In this notebook we will:\n",
    "- Introduce the concept of a pipeline,\n",
    "- Review `sklearn`'s `Pipeline`s and\n",
    "- Fit a polynomial regression using `PolynomialFeatures` and `Pipeline`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(4403)\n",
    "import matplotlib.pyplot as plt\n",
    "from seaborn import set_style\n",
    "set_style(\"whitegrid\")\n",
    "\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is a pipeline?\n",
    "\n",
    "We have done a little bit of data preprocessing up to this point including, scaling and creating new features out of existing features (e.g. polynomial transforms, one-hot encoding and interactions). The concept of a <i>pipeline</i> is a nice framework for combining all of those steps and fitting a model all into one container. Here's a simple visualization that helps explain this concept:\n",
    "\n",
    "<img src=\"lecture_4_assets/pipe.png\" style=\"width:85%\"></img>\n",
    "\n",
    "<i>Mario of the Super Mario Brothers video game franchise is intellectual property of the Nintendo Corporation</i>.\n",
    "\n",
    "## An example in python\n",
    "\n",
    "Let's show how to implement this concept in python by doing an example problem. We will create some synthetic data where we would like to fit a polynomial regression model. \n",
    "\n",
    "In this example we will introduce:\n",
    "- `PolynomialFeatures`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html\">https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html</a> and \n",
    "- `Pipeline`, <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html</a>. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Generating some data\n",
    "x = np.linspace(-3,7.5,1000)\n",
    "y = (x-7)*(x+2)*x + 10*np.random.randn(1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrating the data\n",
    "plt.figure(figsize=(10,5))\n",
    "\n",
    "plt.scatter(x,y,s=10)\n",
    "\n",
    "plt.xlabel(\"$x$\", fontsize=18)\n",
    "plt.ylabel(\"$y$\", fontsize=18)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `PolynomialFeatures`\n",
    "\n",
    "`PolynomialFeatures` is an `sklearn` transformer object (similar to the scaler objects we have discussed) that takes in a 2D `numpy` array and returns a `numpy` array with columns corresponding to all the relevant polynomial transformations of the given `degree`, as illustrated by the image where `degree=2`:\n",
    "\n",
    "<img src=\"lecture_4_assets/polyfeatures.png\" width=\"65%\"></img>\n",
    "\n",
    "<i>Note: columns may not be returned in that order by actual `PolynomialFeatures` transformation.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import PolynomialFeatures\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## demonstrate PolynomialFeatures\n",
    "## the first argument is the degress of the polynomial\n",
    "## the interaction_only term says whether you just want interaction terms returned\n",
    "## include_bias determines whether or not a column of 1s is returned\n",
    "poly = \n",
    "\n",
    "\n",
    "## in keeping with our sklearn objects we need to reshape \n",
    "## the array prior to fitting and transforming the model and array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that just like scaler objects transformer objects also have a `fit`, `transform` and `fit_transform` method. The rules for these are exactly the same as the rules for the scalers. This may seem confusing because it does not seem like `PolynomialFeatures` needs to \"fit\" anything, but it does. For `PolynomialFeatures` the `fit` step reads the shape of the input array and determines what transformations need to occur. In the above example, it sees that the array is a single column, so it needs to return:\n",
    "- That column,\n",
    "- That column squared and\n",
    "- That column cubed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an idea of how `PolynomialFeatures` works let's incorporate this into a `Pipeline`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import Pipeline\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our pipeline we will want to transform $x$ into $x$, $x^2$ and $x^3$ and then use the resulting data to fit the model\n",
    "$$\n",
    "y = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3 + \\epsilon.\n",
    "$$\n",
    "\n",
    "Schematically our pipe will look like this:\n",
    "\n",
    "<img src=\"lecture_4_assets/pipe_example.png\" width=\"60%\"></img>\n",
    "\n",
    "The labels `'poly'` and `'reg'` should be clear soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## make the Pipeline object\n",
    "## Pipeline objects take in a list as an argument\n",
    "## that list contains tuples of the steps you want in your pipeline\n",
    "## In this tuple we want PolynomialFeatures and\n",
    "## LinearRegression\n",
    "## Each tuple has a name for the step as its first entry,\n",
    "## then the python object as its second entry\n",
    "pipe = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Pipeline`'s also have a `fit` method. This is what runs the input and output data through the pipe and fits all relevant transformers and scalers followed by the model. We can call it like we have done for scaler and transformer object `fit` methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## fit the Pipeline object\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pipe is fit we can make predictions like we would for a normal `LinearRegression` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## show we can make predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also access the individual pieces of the pipe and see what is going on in them. Below we access the fit `LinearRegression` object and look at the resulting coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Show how to access individual components of Pipeline\n",
    "## This is done similar to how a dictionary is accessed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a good introduction to `Pipeline`s. Note that while we did not use a `scaler` object, we could have. This particular problem just did not call for scaling the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------\n",
    "\n",
    "This notebook was written for the Erd&#337;s Institute C&#337;de Data Science Boot Camp by Matthew Osborne, Ph. D., 2023.\n",
    "\n",
    "Any potential redistributors must seek and receive permission from Matthew Tyler Osborne, Ph.D. prior to redistribution. Redistribution of the material contained in this repository is conditional on acknowledgement of Matthew Tyler Osborne, Ph.D.'s original authorship and sponsorship of the Erd≈ës Institute as subject to the license (see License.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
